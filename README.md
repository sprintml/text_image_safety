# Beautiful Images, Toxic Words: Understanding and Addressing Offensive Text in Generated Images

This repository contains scripts for different parts of the project:

## ðŸ“‚ Project Structure
- **`NSFW_intervention/`** â€“ Implementation of **NSFW-Intervention**.
- **`NSFW_intervention_CLIP/`** â€“ Implementation of **NSFW-Intervention-CLIP** and **Safe-CLIP**.
- **`AURA_intervention/`** â€“ Custom implementation of **AURA** in the diffusion backbone models of studied text-to-image models.
- **`ToxicBench/`** - Our new dataset and evaluation pipeline.

## ðŸ›  Dependencies & Implementations
- **NSFW_intervention** is implemented based on: [diffusers](https://github.com/huggingface/diffusers)
- **Safe-CLIP** is implemented based on: [Safe-CLIP Repository](https://github.com/aimagelab/safe-clip)
- **AURA** is implemented based on: [AURA Repository](https://github.com/apple/ml-aura)
